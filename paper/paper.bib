@article{Turner2025, doi = {10.21105/joss.08135}, url = {https://doi.org/10.21105/joss.08135}, year = {2025}, publisher = {The Open Journal}, volume = {10}, number = {113}, pages = {8135}, author = {Turner, Joseph I. and Turner, Kaydance D.}, title = {PyPaperRetriever: A Python Tool for Finding and Downloading Scientific Literature}, journal = {Journal of Open Source Software} } 
@article{10.1162/qss_a_00327,
    author = {Hanson, Mark A. and Barreiro, Pablo Gómez and Crosetto, Paolo and Brockington, Dan},
    title = {The strain on scientific publishing},
    journal = {Quantitative Science Studies},
    volume = {5},
    number = {4},
    pages = {823-843},
    year = {2024},
    month = {11},
    abstract = {Scientists are increasingly overwhelmed by the volume of articles being published. The total number of articles indexed in Scopus and Web of Science has grown exponentially in recent years; in 2022 the article total was ∼47\% higher than in 2016, which has outpaced the limited growth—if any—in the number of practicing scientists. Thus, publication workload per scientist has increased dramatically. We define this problem as “the strain on scientific publishing.” To analyze this strain, we present five data-driven metrics showing publisher growth, processing times, and citation behaviors. We draw these data from web scrapes, and from publishers through their websites or upon request. Specific groups have disproportionately grown in their articles published per year, contributing to this strain. Some publishers enabled this growth by hosting “special issues” with reduced turnaround times. Given pressures on researchers to “publish or perish” to compete for funding, this strain was likely amplified by these offers to publish more articles. We also observed widespread year-over-year inflation of journal impact factors coinciding with this strain, which risks confusing quality signals. Such exponential growth cannot be sustained. The metrics we define here should enable this evolving conversation to reach actionable solutions to address the strain on scientific publishing.},
    issn = {2641-3337},
    doi = {10.1162/qss_a_00327},
    url = {https://doi.org/10.1162/qss_a_00327},
    eprint = {https://direct.mit.edu/qss/article-pdf/5/4/823/2478590/qss_a_00327.pdf},
}

@techreport{kitchenham2007guidelines,
	title        = {Guidelines for performing Systematic Literature Reviews in Software Engineering},
	author       = {Kitchenham, Barbara Ann and Charters, Stuart},
	year         = {2007},
	month        = {07},
	day          = {09},
	number       = {EBSE 2007-001},
	url          = {https://www.elsevier.com/\%5F\%5Fdata/promis\%5Fmisc/525444systematicreviewsguide.pdf},
	abstract     = {The objective of this report is to propose comprehensive guidelines for systematic literature reviews appropriate for software engineering researchers, including PhD students. A systematic literature review is a means of evaluating and interpreting all available research relevant to a particular research question, topic area, or phenomenon of interest. Systematic reviews aim to present a fair evaluation of a research topic by using a trustworthy, rigorous, and auditable methodology. The guidelines presented in this report were derived from three existing guidelines used by medical researchers, two books produced by researchers with social science backgrounds and discussions with researchers from other disciplines who are involved in evidence-based practice. The guidelines have been adapted to reflect the specific problems of software engineering research. The guidelines cover three phases of a systematic literature review: planning the review, conducting the review and reporting the review. They provide a relatively high level description. They do not consider the impact of the research questions on the review procedures, nor do they specify in detail the mechanisms needed to perform meta-analysis.},
	added-at     = {2019-11-16T00:31:45.000+0100},
	biburl       = {https://www.bibsonomy.org/bibtex/23f4b30c0fe1435b642467af4cca120ef/jpmor},
	citeulike-article-id = {3955888},
	institution  = {Keele University and Durham University Joint Report},
	interhash    = {aed0229656ada843d3e3f24e5e5c9eb9},
	intrahash    = {3f4b30c0fe1435b642467af4cca120ef},
	language     = {English},
	posted-at    = {2009-01-28 11:17:05},
	priority     = {2},
	school       = {Keele University},
	timestamp    = {2020-10-07T13:36:50.000+0200}
}


@article{kitchenham_systematic_2010,
	title        = {Systematic literature reviews in software engineering – A tertiary study},
	author       = {Kitchenham, Barbara and Pretorius, Rialette and Budgen, David and Pearl Brereton, O. and Turner, Mark and Niazi, Mahmood and Linkman, Stephen},
	volume       = {52},
	number       = {8},
journal = {Information and Software Technology},
	pages        = {792--805},
	doi          = {10.1016/j.infsof.2010.03.006},
	issn         = {09505849},
	url          = {https://linkinghub.elsevier.com/retrieve/pii/S0950584910000467},
	urldate      = {2023-04-07},
	abstract     = {Objective: The aim of this on-going research is to provide an annotated catalogue of {SLRs} available to software engineering researchers and practitioners. This study updates our previous study using a broad automated search. Method: We performed a broad automated search to find {SLRs} published in the time period 1st January 2004 to 30th June 2008. We contrast the number, quality and source of these {SLRs} with {SLRs} found in the original study. Results: Our broad search found an additional 35 {SLRs} corresponding to 33 unique studies. Of these papers, 17 appeared relevant to the undergraduate educational curriculum and 12 appeared of possible interest to practitioners. The number of {SLRs} being published is increasing. The quality of papers in conferences and workshops has improved as more researchers use {SLR} guidelines. Conclusion: {SLRs} appear to have gone past the stage of being used solely by innovators but cannot yet be considered a main stream software engineering research methodology. They are addressing a wide range of topics but still have limitations, such as often failing to assess primary study quality.},
	journaltitle = {Information and Software Technology},
	date         = {2010-08},
    year = {2010},
	langid       = {english}
}

@article{hendricks_crossref_2020,
	title        = {Crossref: The sustainable source of community-owned scholarly metadata},
	shorttitle   = {Crossref},
 journal = {Quantitative Science Studies},
	author       = {Hendricks, Ginny and Tkaczyk, Dominika and Lin, Jennifer and Feeney, Patricia},
	volume       = {1},
	number       = {1},
	pages        = {414--427},
	doi          = {10.1162/qss_a_00022},
	issn         = {2641-3337},
	url          = {https://doi.org/10.1162/qss\%5Fa\%5F00022},
	urldate      = {2023-03-29},
	abstract     = {This paper describes the scholarly metadata collected and made available by Crossref, as well as its importance in the scholarly research ecosystem. Containing over 106 million records and expanding at an average rate of 11\% a year, Crossref's metadata has become one of the major sources of scholarly data for publishers, authors, librarians, funders, and researchers. The metadata set consists of 13 content types, including not only traditional types, such as journals and conference papers, but also data sets, reports, preprints, peer reviews, and grants. The metadata is not limited to basic publication metadata, but can also include abstracts and links to full text, funding and license information, citation links, and the information about corrections, updates, retractions, etc. This scale and breadth make Crossref a valuable source for research in scientometrics, including measuring the growth and impact of science and understanding new trends in scholarly communications. The metadata is available through a number of {APIs}, including {REST} {API} and {OAI}-{PMH}. In this paper, we describe the kind of metadata that Crossref provides and how it is collected and curated. We also look at Crossref's role in the research ecosystem and trends in metadata curation over the years, including the evolution of its citation data provision. We summarize the research used in Crossref's metadata and describe plans that will improve metadata quality and retrieval in the future.},
	journaltitle = {Quantitative Science Studies},
	date         = {2020-02-01},
	year= {2020}
}
@article{wilkinson_fair_2016,
	title        = {The {FAIR} Guiding Principles for scientific data management and stewardship},
	author       = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, {IJsbrand} Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Merc\`{e} and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J. G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and 't Hoen, Peter A. C. and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
	volume       = {3},
	number       = {1},
	pages        = {160018},
	doi          = {10/bdd4},
	issn         = {2052-4463},
	url          = {https://www.nature.com/articles/sdata201618},
	urldate      = {2023-04-14},
	rights       = {2016 The Author(s)},
	abstract     = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders--representing academia, industry, funding agencies, and scholarly publishers--have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the {FAIR} Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the {FAIR} Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the {FAIR} Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
	journaltitle = {Scientific Data},
	shortjournal = {Sci Data},
	date         = {2016-03-15},
	year={2016},
	langid       = {english}
}
@article{peroni_opencitations_2020,
	title        = {{OpenCitations}, an infrastructure organization for open scholarship},
    journal = {Quantitative Science Studies},
	author       = {Peroni, Silvio and Shotton, David},
	volume       = {1},
	number       = {1},
	pages        = {428--444},
	doi          = {https://doi.org/10.1162/qss_a_00023},
	issn         = {2641-3337},
	url          = {https://doi.org/10.1162/qss\%5Fa\%5F00023},
	urldate      = {2023-04-14},
	abstract     = {{OpenCitations} is an infrastructure organization for open scholarship dedicated to the publication of open citation data as Linked Open Data using Semantic Web technologies, thereby providing a disruptive alternative to traditional proprietary citation indexes. Open citation data are valuable for bibliometric analysis, increasing the reproducibility of large-scale analyses by enabling publication of the source data. Following brief introductions to the development and benefits of open scholarship and to Semantic Web technologies, this paper describes {OpenCitations} and its data sets, tools, services, and activities. These include the {OpenCitations} Data Model; the {SPAR} (Semantic Publishing and Referencing) Ontologies; {OpenCitations}' open software of generic applicability for searching, browsing, and providing {REST} {APIs} over resource description framework ({RDF}) triplestores; Open Citation Identifiers ({OCIs}) and the {OpenCitations} {OCI} Resolution Service; the {OpenCitations} Corpus ({OCC}), a database of open downloadable bibliographic and citation data made available in {RDF} under a Creative Commons public domain dedication; and the {OpenCitations} Indexes of open citation data, of which the first and largest is {COCI}, the {OpenCitations} Index of Crossref Open {DOI}-to-{DOI} Citations, which currently contains over 624 million bibliographic citations and is receiving considerable usage by the scholarly community.},
	journaltitle = {Quantitative Science Studies},
	shortjournal = {Quantitative Science Studies},
	date         = {2020-02-01},
	year={2020}
}
@inproceedings{kardas_axcell_2020,
	title        = {{AxCell}: Automatic Extraction of Results from Machine Learning Papers},
	shorttitle   = {{AxCell}},
	author       = {Kardas, Marcin and Czapla, Piotr and Stenetorp, Pontus and Ruder, Sebastian and Riedel, Sebastian and Taylor, Ross and Stojnic, Robert},
	booktitle    = {Proceedings of the 2020 Conference on EMNLP Processing },
	address     = {Online},
	publisher    = {{ACL}},
	pages        = {8580--8594},
	doi          = {10.18653/v1/2020.emnlp-main.692},
	url          = {https://www.aclweb.org/anthology/2020.emnlp-main.692},
	urldate      = {2023-03-29},
	abstract     = {In this paper we . . . state-of-the-art machine translation . . . by 1 {BLEU} score . . . We open source our . . .},
	eventtitle   = {Proceedings of the 2020 Conference on EMNLP Processing },
	year         = {2020},
	langid       = {english}
}
@article{mueen_ahmed_zotero_2011,
	title        = {Zotero: A bibliographic assistant to researcher},
	shorttitle   = {Zotero},
	author       = {Mueen Ahmed, K. K. and Dhubaib, Bandar E. Al},
	volume       = {2},
	number       = {4},
	pages        = {304--305},
journal= {J. Pharmacol Pharmacother},
	doi          = {10.4103/0976-500X.85940},
	issn         = {0976-500X},
	url          = {https://doi.org/10.4103/0976-500X.85940},
	urldate      = {2023-03-29},
	journaltitle = {Journal of Pharmacology and Pharmacotherapeutics},
	date         = {2011-12-01},
	year={2011},
	langid       = {english}
}
@misc{pypaperbot,
  author = {Vito Ferrulli},
  title = {PyPaperBot: A tool to automatically download scientific papers},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  url = {https://github.com/ferru97/PyPaperBot},
  note = {First released on November 8, 2020}
}
